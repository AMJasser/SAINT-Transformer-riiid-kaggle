{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import sys\n","import numpy as np\n","\n","import os\n","import glob\n","import time\n","from os import listdir\n","\n","import sklearn.preprocessing as preprocessing\n","from sklearn.metrics import roc_auc_score\n","\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","\n","from sys import getsizeof\n","\n","#supress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import time\n","import gc\n","import math \n","import pickle\n","import torch"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["group = pd.read_pickle(\"../data/processed/inference_group\")\n","\n","with open('../data/processed/inference_last_timestamp.pickle', 'rb') as handle:\n","    last_timestamp = pickle.load(handle)\n","\n","boundaries = [120,600,1800,3600,10800,43200,86400,259200,604800]\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Loading the model\n","sys.path.append('..')\n","\n","from src.models.model import TransformerModel\n","import yaml\n","\n","with open('../config.yaml') as file:\n","    config = yaml.load(file, Loader=yaml.FullLoader)\n","\n","\n","\n","#Transformer hyperparameter \n","d_model = config[\"d_model\"]\n","\n","decoder_layers = config[\"decoder_layers\"]\n","encoder_layers = config[\"encoder_layers\"]\n","\n","\n","correct_start_token = config[\"correct_start_token\"]\n","user_answer_start_token = config[\"user_answer_start_token\"]\n","seq_len = config[\"seq_len\"]\n","\n","dropout = config[\"dropout\"]\n","ff_model = d_model*4\n","att_heads = d_model // 64\n","\n","\n","#Loading questions, and every question corresponding part\n","que_data = pd.read_csv( \"../data/raw/questions.csv\")\n","part_valus = que_data.part.values\n","unique_ques = len(que_data)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","part_valus = torch.LongTensor(part_valus).to(device)\n","que_emb_size = unique_ques\n","\n","model = TransformerModel(que_emb_size, hidden=d_model,part_arr=part_valus, dec_layers=decoder_layers, enc_layers=encoder_layers, dropout=dropout, nheads=att_heads, ff_model=ff_model).to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["TransformerModel(\n","  (encoder): Embedding(13523, 64)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): Embedding(3, 64)\n","  (pos_decoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer): Transformer(\n","    (encoder): TransformerEncoder(\n","      (layers): ModuleList(\n","        (0): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): TransformerDecoder(\n","      (layers): ModuleList(\n","        (0): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n","  (part_embedding): Embedding(7, 64)\n","  (ts_embedding): Embedding(70, 64)\n","  (user_answer_embedding): Embedding(5, 64)\n","  (dropout_1): Dropout(p=0.1, inplace=False)\n","  (dropout_2): Dropout(p=0.1, inplace=False)\n","  (dropout_3): Dropout(p=0.1, inplace=False)\n","  (dropout_4): Dropout(p=0.1, inplace=False)\n","  (dropout_5): Dropout(p=0.1, inplace=False)\n","  (dropout_6): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"../models/model_best.torch\"))\n","model.eval()"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def pred_users(vals): #Input must be (eval_batch, 3): [\"user_id\", \"content_id\", \"content_type_id\", \"timestamp\"]\n","\n","    eval_batch = vals.shape[0]\n","\n","    tensor_question = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_answers = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_ts = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_user_answer = np.zeros((eval_batch, seq_len), dtype=np.long)\n","\n","\n","    val_len = []\n","    preds = []\n","    group_index = group.index\n","\n","    for i, line in enumerate(vals):\n","\n","        if line[2] == True:\n","            val_len.append(0)\n","            continue\n","\n","        user_id = line[0]\n","        question_id = line[1]\n","        timestamp = get_timestamp(line[3], user_id) #Compute timestamp difference correctly\n","        \n","\n","        que_history = np.array([], dtype=np.int32)\n","        answers_history = np.array([], dtype=np.int32)  \n","        ts_history = np.array([], dtype=np.int32)  \n","        user_answer_history = np.array([], dtype=np.int32)  \n","\n","        if user_id in group_index:\n","\n","            cap = seq_len-1\n","            que_history, answers_history, ts_history, user_answer_history = group[user_id]\n","\n","            que_history = que_history[-cap:]\n","            answers_history = answers_history[-cap:]\n","            ts_history = ts_history[-cap:]\n","            user_answer_history = user_answer_history[-cap:]\n","\n","\n","        #Decoder data, add start token\n","        answers_history = np.concatenate(([correct_start_token],answers_history))\n","        user_answer_history = np.concatenate(([user_answer_start_token],user_answer_history))\n","\n","        #Decoder data\n","        que_history = np.concatenate((que_history, [question_id]))  #Add current question\n","        ts_history = np.concatenate((ts_history, [timestamp]))  \n","\n","        tensor_question[i][:len(que_history)] = que_history\n","        tensor_answers[i][:len(que_history)] = answers_history\n","        tensor_ts[i][:len(que_history)] = ts_history\n","        tensor_user_answer[i][:len(que_history)] = user_answer_history\n","\n","        val_len.append(len(que_history))\n","\n","    tensor_question = torch.from_numpy(tensor_question).long().T.to(device)\n","    tensor_answers = torch.from_numpy(tensor_answers).long().T.to(device)\n","    tensor_ts = torch.from_numpy(tensor_ts).long().T.to(device)\n","    tensor_user_answer = torch.from_numpy(tensor_user_answer).long().T.to(device)\n","    \n","    with torch.no_grad():   #Disable gradients so prediction runs faster\n","        out = F.sigmoid(model(tensor_question, tensor_answers, tensor_ts, tensor_user_answer)).squeeze(dim=-1).T\n","\n","\n","    for j in range(len(val_len)):\n","        preds.append(out[j][val_len[j]-1].item())\n","\n","    return preds"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def update_group_var(vals):\n","    \n","    global group\n","    \n","    for i, line in enumerate(vals):\n","        \n","        user_id = line[0]\n","        question_id = line[1]\n","        \n","        content_type_id = line[2]\n","        ts = get_timestamp(line[3], user_id)\n","        \n","        correct = line[4]\n","        user_answer = line[5]\n","        \n","        \n","        if content_type_id == True:\n","            continue\n","\n","        if last_timestamp.get(user_id, -1) == -1:\n","            last_timestamp[user_id] = 0\n","        else:\n","            last_timestamp[user_id] = line[3]\n","            \n","        if user_id in group.index:\n","            questions= np.append(group[user_id][0],[question_id])\n","            answers= np.append(group[user_id][1],[correct])\n","            ts= np.append(group[user_id][2],[ts])\n","            user_answer= np.append(group[user_id][3],[user_answer])\n","            \n","            group[user_id] = (questions, answers, ts, user_answer)\n","        else:\n","            group[user_id] = (np.array([question_id], dtype=np.int32), np.array([correct], dtype=np.int32), np.array([ts], dtype=np.int32)\n","                             ,np.array([user_answer], dtype=np.int32))"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["#Re-creates the timestamp encoding\n","def get_timestamp(ts, user_id):\n","    \n","    if last_timestamp.get(user_id, -1) == -1:\n","        return 0\n","    \n","    diff = (ts - last_timestamp[user_id])/1000\n","    \n","    if diff < 0:\n","        return 0\n","    \n","    if diff <= 60:\n","        return int(diff)\n","    \n","    for i, boundary in enumerate(boundaries):\n","        if boundary > diff:\n","            break\n","            \n","    if i == len(boundaries) - 1:\n","        return 60+i+1\n","    \n","    return 60+i"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["#Tito's iterator: https://www.kaggle.com/its7171/time-series-api-iter-test-emulator\n","\n","class Iter_Valid(object):\n","    def __init__(self, df, max_user=1000):\n","        df = df.reset_index(drop=True)\n","        self.df = df\n","        self.user_answer = df['user_answer'].astype(str).values\n","        self.answered_correctly = df['answered_correctly'].astype(str).values\n","        df['prior_group_responses'] = \"[]\"\n","        df['prior_group_answers_correct'] = \"[]\"\n","        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n","        self.sample_df['answered_correctly'] = 0\n","        self.len = len(df)\n","        self.user_id = df.user_id.values\n","        self.task_container_id = df.task_container_id.values\n","        self.content_type_id = df.content_type_id.values\n","        self.max_user = max_user\n","        self.current = 0\n","        self.pre_user_answer_list = []\n","        self.pre_answered_correctly_list = []\n","\n","    def __iter__(self):\n","        return self\n","    \n","    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n","        df= self.df[pre_start:self.current].copy()\n","        sample_df = self.sample_df[pre_start:self.current].copy()\n","        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n","        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n","        self.pre_user_answer_list = user_answer_list\n","        self.pre_answered_correctly_list = answered_correctly_list\n","        return df, sample_df\n","\n","    def __next__(self):\n","        added_user = set()\n","        pre_start = self.current\n","        pre_added_user = -1\n","        pre_task_container_id = -1\n","\n","        user_answer_list = []\n","        answered_correctly_list = []\n","        while self.current < self.len:\n","            crr_user_id = self.user_id[self.current]\n","            crr_task_container_id = self.task_container_id[self.current]\n","            crr_content_type_id = self.content_type_id[self.current]\n","            if crr_content_type_id == 1:\n","                # no more than one task_container_id of \"questions\" from any single user\n","                # so we only care for content_type_id == 0 to break loop\n","                user_answer_list.append(self.user_answer[self.current])\n","                answered_correctly_list.append(self.answered_correctly[self.current])\n","                self.current += 1\n","                continue\n","            if crr_user_id in added_user and ((crr_user_id != pre_added_user) or (crr_task_container_id != pre_task_container_id)):\n","                # known user(not prev user or differnt task container)\n","                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            if len(added_user) == self.max_user:\n","                if  crr_user_id == pre_added_user and crr_task_container_id == pre_task_container_id:\n","                    user_answer_list.append(self.user_answer[self.current])\n","                    answered_correctly_list.append(self.answered_correctly[self.current])\n","                    self.current += 1\n","                    continue\n","                else:\n","                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            added_user.add(crr_user_id)\n","            pre_added_user = crr_user_id\n","            pre_task_container_id = crr_task_container_id\n","            user_answer_list.append(self.user_answer[self.current])\n","            answered_correctly_list.append(self.answered_correctly[self.current])\n","            self.current += 1\n","        if pre_start < self.current:\n","            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","        else:\n","            raise StopIteration()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["validation = pd.read_pickle(\"../data/interim/cv_valid.pickle\")"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["iter_test = Iter_Valid(validation,max_user=1000)\n","predicted = []\n","def set_predict(df):\n","    predicted.append(df)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.42754068970680237]\n","[[  564210065        4696           0      369239]\n"," [ 1561519675        4806           0 11135937974]\n"," [ 2097276246        4983           0  1556204317]\n"," [ 1711120145        8811           0  5115667030]\n"," [ 2147482216         992           0  1309013474]\n"," [ 1439398920        5698           0   151851604]\n"," [  331356028        6185           0 21633783555]\n"," [ 1125679392        6453           0  1505063027]\n"," [  508071892        5177           0 29445253296]\n"," [ 1089707405         627           0     1119952]\n"," [ 1967034370        2208           0  4564316871]\n"," [ 1967034370        2207           0  4564316871]\n"," [ 1967034370        2206           0  4564316871]\n"," [   54995956        3704           0   487025653]]\n","[0.42754068970680237, 0.8213961124420166, 0.8142706155776978, 0.44231030344963074, 0.9109843373298645, 0.5573331713676453, 0.5319108963012695, 0.2682316303253174, 0.47369757294654846, 0.7033225893974304, 0.5745517015457153, 0.6780522465705872, 0.5348677039146423, 0.782965898513794]\n"]}],"source":["i = 0\n","\n","for (test_df, sample_prediction_df) in iter_test:\n","    data = test_df[[\"user_id\",\"content_id\",\"content_type_id\",\"timestamp\"]].values\n","    preds = pred_users(data);\n","    \n","    i += 1\n","\n","    print(pred_users(torch.Tensor([pd.DataFrame(data).iloc[0].to_numpy()])))\n","    print(data)\n","    print(preds)\n","\n","    if (i == 1):\n","        break;"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 20719/2530758 [00:26<43:37, 958.85it/s]  "]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:22\u001b[0m\n","Cell \u001b[0;32mIn [6], line 63\u001b[0m, in \u001b[0;36mpred_users\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m     60\u001b[0m tensor_user_answer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(tensor_user_answer)\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     62\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():   \u001b[39m#Disable gradients so prediction runs faster\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49msigmoid(model(tensor_question, tensor_answers, tensor_ts, tensor_user_answer))\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mT\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(val_len)):\n\u001b[1;32m     67\u001b[0m     preds\u001b[39m.\u001b[39mappend(out[j][val_len[j]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mitem())\n","File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/functional.py:1967\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1960\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msigmoid\u001b[39m(\u001b[39minput\u001b[39m):\n\u001b[1;32m   1961\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"sigmoid(input) -> Tensor\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \n\u001b[1;32m   1963\u001b[0m \u001b[39m    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \n\u001b[1;32m   1965\u001b[0m \u001b[39m    See :class:`~torch.nn.Sigmoid` for more details.\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1967\u001b[0m     warnings\u001b[39m.\u001b[39;49mwarn(\u001b[39m\"\u001b[39;49m\u001b[39mnn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1968\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msigmoid()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","import ast\n","from tqdm import tqdm\n","\n","model.eval()\n","\n","preds = []\n","pbar = tqdm(total=validation.shape[0], position=0, leave=True)\n","check = None\n","\n","for (test_data, current_prediction_df) in iter_test:   \n","        \n","    if check is not None:\n","        past_vals = np.array(ast.literal_eval(test_data.iloc[0].prior_group_answers_correct)) \n","        past_answers = np.array(ast.literal_eval(test_data.iloc[0].prior_group_responses))\n","\n","        past_vals = np.concatenate((vals, past_vals.reshape(len(past_vals),1)), axis=1)\n","        past_vals = np.concatenate((past_vals, past_answers.reshape(len(past_answers),1)), axis=1)\n","\n","        update_group_var(past_vals)  #Update database with the vals of the last batch        \n","        \n","    vals = test_data[[\"user_id\",\"content_id\",\"content_type_id\",\"timestamp\"]].values\n","    preds.extend(pred_users(vals))\n","    \n","    check = 1\n","\n","    pbar.update(len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Validation ROC: 0.7879732810648672\n","100%|██████████| 254021/254021 [25:51<00:00, 80.02it/s]"]}],"source":["df = validation.iloc[:len(preds)]\n","df[\"preds\"] = preds\n","\n","df = df[df.content_type_id == False]\n","print('Validation ROC:',roc_auc_score(df.answered_correctly, df.preds))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
