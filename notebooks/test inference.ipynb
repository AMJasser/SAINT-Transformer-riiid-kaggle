{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["import sys\n","import numpy as np\n","\n","import os\n","import glob\n","import time\n","from os import listdir\n","\n","import sklearn.preprocessing as preprocessing\n","from sklearn.metrics import roc_auc_score\n","\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","\n","from sys import getsizeof\n","\n","#supress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import time\n","import gc\n","import math \n","import pickle\n","import torch"],"execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["group = pd.read_pickle(\"../data/processed/inference_group\")\n","\n","with open('../data/processed/inference_last_timestamp.pickle', 'rb') as handle:\n","    last_timestamp = pickle.load(handle)\n","\n","boundaries = [120,600,1800,3600,10800,43200,86400,259200,604800]\n"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2500000 [01:09<?, ?it/s]\n"]}]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["#Loading the model\n","sys.path.append('..')\n","\n","from src.models.model import TransformerModel\n","import yaml\n","\n","with open('../config.yaml') as file:\n","    config = yaml.load(file, Loader=yaml.FullLoader)\n","\n","\n","\n","#Transformer hyperparameter \n","d_model = config[\"d_model\"]\n","\n","decoder_layers = config[\"decoder_layers\"]\n","encoder_layers = config[\"encoder_layers\"]\n","\n","\n","correct_start_token = config[\"correct_start_token\"]\n","user_answer_start_token = config[\"user_answer_start_token\"]\n","seq_len = config[\"seq_len\"]\n","\n","dropout = config[\"dropout\"]\n","ff_model = d_model*4\n","att_heads = d_model // 64\n","\n","\n","#Loading questions, and every question corresponding part\n","que_data = pd.read_csv( \"../data/raw/questions.csv\")\n","part_valus = que_data.part.values\n","unique_ques = len(que_data)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","part_valus = torch.LongTensor(part_valus).to(device)\n","que_emb_size = unique_ques\n","\n","model = TransformerModel(que_emb_size, hidden=d_model,part_arr=part_valus, dec_layers=decoder_layers, enc_layers=encoder_layers, dropout=dropout, nheads=att_heads, ff_model=ff_model).to(device)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":60}],"source":["model.load_state_dict(torch.load(\"../models/model_best.torch\"))\n","model.eval()"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def pred_users(vals): #Input must be (eval_batch, 3): [\"user_id\", \"content_id\", \"content_type_id\", \"timestamp\"]\n","\n","    eval_batch = vals.shape[0]\n","\n","    tensor_question = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_answers = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_ts = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_user_answer = np.zeros((eval_batch, seq_len), dtype=np.long)\n","\n","\n","    val_len = []\n","    preds = []\n","    group_index = group.index\n","\n","    for i, line in enumerate(vals):\n","\n","        if line[2] == True:\n","            val_len.append(0)\n","            continue\n","\n","        user_id = line[0]\n","        question_id = line[1]\n","        timestamp = get_timestamp(line[3], user_id) #Compute timestamp difference correctly\n","        \n","\n","        que_history = np.array([], dtype=np.int32)\n","        answers_history = np.array([], dtype=np.int32)  \n","        ts_history = np.array([], dtype=np.int32)  \n","        user_answer_history = np.array([], dtype=np.int32)  \n","\n","        if user_id in group_index:\n","\n","            cap = seq_len-1\n","            que_history, answers_history, ts_history, user_answer_history = group[user_id]\n","\n","            que_history = que_history[-cap:]\n","            answers_history = answers_history[-cap:]\n","            ts_history = ts_history[-cap:]\n","            user_answer_history = user_answer_history[-cap:]\n","\n","\n","        #Decoder data, add start token\n","        answers_history = np.concatenate(([correct_start_token],answers_history))\n","        user_answer_history = np.concatenate(([user_answer_start_token],user_answer_history))\n","\n","        #Decoder data\n","        que_history = np.concatenate((que_history, [question_id]))  #Add current question\n","        ts_history = np.concatenate((ts_history, [timestamp]))  \n","\n","        tensor_question[i][:len(que_history)] = que_history\n","        tensor_answers[i][:len(que_history)] = answers_history\n","        tensor_ts[i][:len(que_history)] = ts_history\n","        tensor_user_answer[i][:len(que_history)] = user_answer_history\n","\n","        val_len.append(len(que_history))\n","\n","    tensor_question = torch.from_numpy(tensor_question).long().T.to(device)\n","    tensor_answers = torch.from_numpy(tensor_answers).long().T.to(device)\n","    tensor_ts = torch.from_numpy(tensor_ts).long().T.to(device)\n","    tensor_user_answer = torch.from_numpy(tensor_user_answer).long().T.to(device)\n","    \n","    with torch.no_grad():   #Disable gradients so prediction runs faster\n","        out = F.sigmoid(model(tensor_question, tensor_answers, tensor_ts, tensor_user_answer)).squeeze(dim=-1).T\n","\n","\n","    for j in range(len(val_len)):\n","        preds.append(out[j][val_len[j]-1].item())\n","\n","    return preds"],"execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def update_group_var(vals):\n","    \n","    global group\n","    \n","    for i, line in enumerate(vals):\n","        \n","        user_id = line[0]\n","        question_id = line[1]\n","        \n","        content_type_id = line[2]\n","        ts = get_timestamp(line[3], user_id)\n","        \n","        correct = line[4]\n","        user_answer = line[5]\n","        \n","        \n","        if content_type_id == True:\n","            continue\n","\n","        if last_timestamp.get(user_id, -1) == -1:\n","            last_timestamp[user_id] = 0\n","        else:\n","            last_timestamp[user_id] = line[3]\n","            \n","        if user_id in group.index:\n","            questions= np.append(group[user_id][0],[question_id])\n","            answers= np.append(group[user_id][1],[correct])\n","            ts= np.append(group[user_id][2],[ts])\n","            user_answer= np.append(group[user_id][3],[user_answer])\n","            \n","            group[user_id] = (questions, answers, ts, user_answer)\n","        else:\n","            group[user_id] = (np.array([question_id], dtype=np.int32), np.array([correct], dtype=np.int32), np.array([ts], dtype=np.int32)\n","                             ,np.array([user_answer], dtype=np.int32))"],"execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Re-creates the timestamp encoding\n","def get_timestamp(ts, user_id):\n","    \n","    if last_timestamp.get(user_id, -1) == -1:\n","        return 0\n","    \n","    diff = (ts - last_timestamp[user_id])/1000\n","    \n","    if diff < 0:\n","        return 0\n","    \n","    if diff <= 60:\n","        return int(diff)\n","    \n","    for i, boundary in enumerate(boundaries):\n","        if boundary > diff:\n","            break\n","            \n","    if i == len(boundaries) - 1:\n","        return 60+i+1\n","    \n","    return 60+i"],"execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Tito's iterator: https://www.kaggle.com/its7171/time-series-api-iter-test-emulator\n","\n","class Iter_Valid(object):\n","    def __init__(self, df, max_user=1000):\n","        df = df.reset_index(drop=True)\n","        self.df = df\n","        self.user_answer = df['user_answer'].astype(str).values\n","        self.answered_correctly = df['answered_correctly'].astype(str).values\n","        df['prior_group_responses'] = \"[]\"\n","        df['prior_group_answers_correct'] = \"[]\"\n","        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n","        self.sample_df['answered_correctly'] = 0\n","        self.len = len(df)\n","        self.user_id = df.user_id.values\n","        self.task_container_id = df.task_container_id.values\n","        self.content_type_id = df.content_type_id.values\n","        self.max_user = max_user\n","        self.current = 0\n","        self.pre_user_answer_list = []\n","        self.pre_answered_correctly_list = []\n","\n","    def __iter__(self):\n","        return self\n","    \n","    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n","        df= self.df[pre_start:self.current].copy()\n","        sample_df = self.sample_df[pre_start:self.current].copy()\n","        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n","        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n","        self.pre_user_answer_list = user_answer_list\n","        self.pre_answered_correctly_list = answered_correctly_list\n","        return df, sample_df\n","\n","    def __next__(self):\n","        added_user = set()\n","        pre_start = self.current\n","        pre_added_user = -1\n","        pre_task_container_id = -1\n","\n","        user_answer_list = []\n","        answered_correctly_list = []\n","        while self.current < self.len:\n","            crr_user_id = self.user_id[self.current]\n","            crr_task_container_id = self.task_container_id[self.current]\n","            crr_content_type_id = self.content_type_id[self.current]\n","            if crr_content_type_id == 1:\n","                # no more than one task_container_id of \"questions\" from any single user\n","                # so we only care for content_type_id == 0 to break loop\n","                user_answer_list.append(self.user_answer[self.current])\n","                answered_correctly_list.append(self.answered_correctly[self.current])\n","                self.current += 1\n","                continue\n","            if crr_user_id in added_user and ((crr_user_id != pre_added_user) or (crr_task_container_id != pre_task_container_id)):\n","                # known user(not prev user or differnt task container)\n","                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            if len(added_user) == self.max_user:\n","                if  crr_user_id == pre_added_user and crr_task_container_id == pre_task_container_id:\n","                    user_answer_list.append(self.user_answer[self.current])\n","                    answered_correctly_list.append(self.answered_correctly[self.current])\n","                    self.current += 1\n","                    continue\n","                else:\n","                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            added_user.add(crr_user_id)\n","            pre_added_user = crr_user_id\n","            pre_task_container_id = crr_task_container_id\n","            user_answer_list.append(self.user_answer[self.current])\n","            answered_correctly_list.append(self.answered_correctly[self.current])\n","            self.current += 1\n","        if pre_start < self.current:\n","            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","        else:\n","            raise StopIteration()"],"execution_count":36,"outputs":[]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["validation = pd.read_pickle(\"../data/interim/cv_valid.pickle\")"]},{"metadata":{"trusted":true},"cell_type":"code","source":["iter_test = Iter_Valid(validation,max_user=1000)\n","predicted = []\n","def set_predict(df):\n","    predicted.append(df)"],"execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["%%time\n","import ast\n","from tqdm import tqdm\n","\n","model.eval()\n","\n","preds = []\n","pbar = tqdm(total=validation.shape[0], position=0, leave=True)\n","check = None\n","\n","for (test_data, current_prediction_df) in iter_test:   \n","        \n","    if check is not None:\n","        past_vals = np.array(ast.literal_eval(test_data.iloc[0].prior_group_answers_correct)) \n","        past_answers = np.array(ast.literal_eval(test_data.iloc[0].prior_group_responses))\n","\n","        past_vals = np.concatenate((vals, past_vals.reshape(len(past_vals),1)), axis=1)\n","        past_vals = np.concatenate((past_vals, past_answers.reshape(len(past_answers),1)), axis=1)\n","\n","        update_group_var(past_vals)  #Update database with the vals of the last batch        \n","        \n","    vals = test_data[[\"user_id\",\"content_id\",\"content_type_id\",\"timestamp\"]].values\n","    preds.extend(pred_users(vals))\n","    \n","    check = 1\n","\n","    pbar.update(len(test_data))"],"execution_count":65,"outputs":[{"output_type":"stream","name":"stderr","text":["  4%|▍         | 1158/27272 [00:08<03:16, 133.03it/s]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32m<ipython-input-33-46940f68f297>\u001b[0m in \u001b[0;36mpred_users\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m#Disable gradients so prediction runs faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_question\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_answers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_user_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\marox\\Documents\\SAINT\\transformer_saint_riiid\\src\\models\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, trg, ts, user_answer)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"the feature number of src and tgt must be equal to d_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[0;32m    125\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[0;32m    294\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m    977\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4220\u001b[0m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_proj_weight_non_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4221\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_proj_weight_non_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4222\u001b[1;33m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = validation.iloc[:len(preds)]\n","df[\"preds\"] = preds\n","\n","df = df[df.content_type_id == False]\n","print('Validation ROC:',roc_auc_score(df.answered_correctly, df.preds))"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation ROC: 0.5181898138018086\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.9.1-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}