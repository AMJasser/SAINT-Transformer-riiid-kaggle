{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["import sys\n","import numpy as np\n","\n","import os\n","import glob\n","import time\n","from os import listdir\n","\n","import sklearn.preprocessing as preprocessing\n","from sklearn.metrics import roc_auc_score\n","\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","\n","from sys import getsizeof\n","\n","#supress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import time\n","import gc\n","import math \n","import pickle\n","import torch"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["group = pd.read_pickle(\"../data/processed/inference_group\")\n","\n","with open('../data/processed/inference_last_timestamp.pickle', 'rb') as handle:\n","    last_timestamp = pickle.load(handle)\n","\n","boundaries = [120,600,1800,3600,10800,43200,86400,259200,604800]\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Loading the model\n","sys.path.append('..')\n","\n","from src.models.model import TransformerModel\n","import yaml\n","\n","with open('../config.yaml') as file:\n","    config = yaml.load(file, Loader=yaml.FullLoader)\n","\n","\n","\n","#Transformer hyperparameter \n","d_model = config[\"d_model\"]\n","\n","decoder_layers = config[\"decoder_layers\"]\n","encoder_layers = config[\"encoder_layers\"]\n","\n","\n","correct_start_token = config[\"correct_start_token\"]\n","user_answer_start_token = config[\"user_answer_start_token\"]\n","seq_len = config[\"seq_len\"]\n","\n","dropout = config[\"dropout\"]\n","ff_model = d_model*4\n","att_heads = d_model // 64\n","\n","\n","#Loading questions, and every question corresponding part\n","que_data = pd.read_csv( \"../data/raw/questions.csv\")\n","part_valus = que_data.part.values\n","unique_ques = len(que_data)\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","part_valus = torch.LongTensor(part_valus).to(device)\n","que_emb_size = unique_ques\n","\n","model = TransformerModel(que_emb_size, hidden=d_model,part_arr=part_valus, dec_layers=decoder_layers, enc_layers=encoder_layers, dropout=dropout, nheads=att_heads, ff_model=ff_model).to(device)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (encoder): Embedding(13523, 64)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): Embedding(3, 64)\n","  (pos_decoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer): Transformer(\n","    (encoder): TransformerEncoder(\n","      (layers): ModuleList(\n","        (0): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): TransformerDecoder(\n","      (layers): ModuleList(\n","        (0): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=64, out_features=64, bias=True)\n","          )\n","          (linear1): Linear(in_features=64, out_features=256, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=256, out_features=64, bias=True)\n","          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n","  (part_embedding): Embedding(7, 64)\n","  (ts_embedding): Embedding(70, 64)\n","  (user_answer_embedding): Embedding(5, 64)\n","  (dropout_1): Dropout(p=0.1, inplace=False)\n","  (dropout_2): Dropout(p=0.1, inplace=False)\n","  (dropout_3): Dropout(p=0.1, inplace=False)\n","  (dropout_4): Dropout(p=0.1, inplace=False)\n","  (dropout_5): Dropout(p=0.1, inplace=False)\n","  (dropout_6): Dropout(p=0.1, inplace=False)\n",")"]},"metadata":{},"execution_count":4}],"source":["model.load_state_dict(torch.load(\"../models/model_best.torch\"))\n","model.eval()"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def pred_users(vals): #Input must be (eval_batch, 3): [\"user_id\", \"content_id\", \"content_type_id\", \"timestamp\"]\n","\n","    eval_batch = vals.shape[0]\n","\n","    tensor_question = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_answers = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_ts = np.zeros((eval_batch, seq_len), dtype=np.long)\n","    tensor_user_answer = np.zeros((eval_batch, seq_len), dtype=np.long)\n","\n","\n","    val_len = []\n","    preds = []\n","    group_index = group.index\n","\n","    for i, line in enumerate(vals):\n","\n","        if line[2] == True:\n","            val_len.append(0)\n","            continue\n","\n","        user_id = line[0]\n","        question_id = line[1]\n","        timestamp = get_timestamp(line[3], user_id) #Compute timestamp difference correctly\n","        \n","\n","        que_history = np.array([], dtype=np.int32)\n","        answers_history = np.array([], dtype=np.int32)  \n","        ts_history = np.array([], dtype=np.int32)  \n","        user_answer_history = np.array([], dtype=np.int32)  \n","\n","        if user_id in group_index:\n","\n","            cap = seq_len-1\n","            que_history, answers_history, ts_history, user_answer_history = group[user_id]\n","\n","            que_history = que_history[-cap:]\n","            answers_history = answers_history[-cap:]\n","            ts_history = ts_history[-cap:]\n","            user_answer_history = user_answer_history[-cap:]\n","\n","\n","        #Decoder data, add start token\n","        answers_history = np.concatenate(([correct_start_token],answers_history))\n","        user_answer_history = np.concatenate(([user_answer_start_token],user_answer_history))\n","\n","        #Decoder data\n","        que_history = np.concatenate((que_history, [question_id]))  #Add current question\n","        ts_history = np.concatenate((ts_history, [timestamp]))  \n","\n","        tensor_question[i][:len(que_history)] = que_history\n","        tensor_answers[i][:len(que_history)] = answers_history\n","        tensor_ts[i][:len(que_history)] = ts_history\n","        tensor_user_answer[i][:len(que_history)] = user_answer_history\n","\n","        val_len.append(len(que_history))\n","\n","    tensor_question = torch.from_numpy(tensor_question).long().T.to(device)\n","    tensor_answers = torch.from_numpy(tensor_answers).long().T.to(device)\n","    tensor_ts = torch.from_numpy(tensor_ts).long().T.to(device)\n","    tensor_user_answer = torch.from_numpy(tensor_user_answer).long().T.to(device)\n","    \n","    with torch.no_grad():   #Disable gradients so prediction runs faster\n","        out = F.sigmoid(model(tensor_question, tensor_answers, tensor_ts, tensor_user_answer)).squeeze(dim=-1).T\n","\n","\n","    for j in range(len(val_len)):\n","        preds.append(out[j][val_len[j]-1].item())\n","\n","    return preds"],"execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def update_group_var(vals):\n","    \n","    global group\n","    \n","    for i, line in enumerate(vals):\n","        \n","        user_id = line[0]\n","        question_id = line[1]\n","        \n","        content_type_id = line[2]\n","        ts = get_timestamp(line[3], user_id)\n","        \n","        correct = line[4]\n","        user_answer = line[5]\n","        \n","        \n","        if content_type_id == True:\n","            continue\n","\n","        if last_timestamp.get(user_id, -1) == -1:\n","            last_timestamp[user_id] = 0\n","        else:\n","            last_timestamp[user_id] = line[3]\n","            \n","        if user_id in group.index:\n","            questions= np.append(group[user_id][0],[question_id])\n","            answers= np.append(group[user_id][1],[correct])\n","            ts= np.append(group[user_id][2],[ts])\n","            user_answer= np.append(group[user_id][3],[user_answer])\n","            \n","            group[user_id] = (questions, answers, ts, user_answer)\n","        else:\n","            group[user_id] = (np.array([question_id], dtype=np.int32), np.array([correct], dtype=np.int32), np.array([ts], dtype=np.int32)\n","                             ,np.array([user_answer], dtype=np.int32))"],"execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Re-creates the timestamp encoding\n","def get_timestamp(ts, user_id):\n","    \n","    if last_timestamp.get(user_id, -1) == -1:\n","        return 0\n","    \n","    diff = (ts - last_timestamp[user_id])/1000\n","    \n","    if diff < 0:\n","        return 0\n","    \n","    if diff <= 60:\n","        return int(diff)\n","    \n","    for i, boundary in enumerate(boundaries):\n","        if boundary > diff:\n","            break\n","            \n","    if i == len(boundaries) - 1:\n","        return 60+i+1\n","    \n","    return 60+i"],"execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#Tito's iterator: https://www.kaggle.com/its7171/time-series-api-iter-test-emulator\n","\n","class Iter_Valid(object):\n","    def __init__(self, df, max_user=1000):\n","        df = df.reset_index(drop=True)\n","        self.df = df\n","        self.user_answer = df['user_answer'].astype(str).values\n","        self.answered_correctly = df['answered_correctly'].astype(str).values\n","        df['prior_group_responses'] = \"[]\"\n","        df['prior_group_answers_correct'] = \"[]\"\n","        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n","        self.sample_df['answered_correctly'] = 0\n","        self.len = len(df)\n","        self.user_id = df.user_id.values\n","        self.task_container_id = df.task_container_id.values\n","        self.content_type_id = df.content_type_id.values\n","        self.max_user = max_user\n","        self.current = 0\n","        self.pre_user_answer_list = []\n","        self.pre_answered_correctly_list = []\n","\n","    def __iter__(self):\n","        return self\n","    \n","    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n","        df= self.df[pre_start:self.current].copy()\n","        sample_df = self.sample_df[pre_start:self.current].copy()\n","        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n","        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n","        self.pre_user_answer_list = user_answer_list\n","        self.pre_answered_correctly_list = answered_correctly_list\n","        return df, sample_df\n","\n","    def __next__(self):\n","        added_user = set()\n","        pre_start = self.current\n","        pre_added_user = -1\n","        pre_task_container_id = -1\n","\n","        user_answer_list = []\n","        answered_correctly_list = []\n","        while self.current < self.len:\n","            crr_user_id = self.user_id[self.current]\n","            crr_task_container_id = self.task_container_id[self.current]\n","            crr_content_type_id = self.content_type_id[self.current]\n","            if crr_content_type_id == 1:\n","                # no more than one task_container_id of \"questions\" from any single user\n","                # so we only care for content_type_id == 0 to break loop\n","                user_answer_list.append(self.user_answer[self.current])\n","                answered_correctly_list.append(self.answered_correctly[self.current])\n","                self.current += 1\n","                continue\n","            if crr_user_id in added_user and ((crr_user_id != pre_added_user) or (crr_task_container_id != pre_task_container_id)):\n","                # known user(not prev user or differnt task container)\n","                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            if len(added_user) == self.max_user:\n","                if  crr_user_id == pre_added_user and crr_task_container_id == pre_task_container_id:\n","                    user_answer_list.append(self.user_answer[self.current])\n","                    answered_correctly_list.append(self.answered_correctly[self.current])\n","                    self.current += 1\n","                    continue\n","                else:\n","                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","            added_user.add(crr_user_id)\n","            pre_added_user = crr_user_id\n","            pre_task_container_id = crr_task_container_id\n","            user_answer_list.append(self.user_answer[self.current])\n","            answered_correctly_list.append(self.answered_correctly[self.current])\n","            self.current += 1\n","        if pre_start < self.current:\n","            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n","        else:\n","            raise StopIteration()"],"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["validation = pd.read_pickle(\"../data/interim/cv_valid.pickle\")"]},{"metadata":{"trusted":true},"cell_type":"code","source":["iter_test = Iter_Valid(validation,max_user=1000)\n","predicted = []\n","def set_predict(df):\n","    predicted.append(df)"],"execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["%%time\n","import ast\n","from tqdm import tqdm\n","\n","model.eval()\n","\n","preds = []\n","pbar = tqdm(total=validation.shape[0], position=0, leave=True)\n","check = None\n","\n","for (test_data, current_prediction_df) in iter_test:   \n","        \n","    if check is not None:\n","        past_vals = np.array(ast.literal_eval(test_data.iloc[0].prior_group_answers_correct)) \n","        past_answers = np.array(ast.literal_eval(test_data.iloc[0].prior_group_responses))\n","\n","        past_vals = np.concatenate((vals, past_vals.reshape(len(past_vals),1)), axis=1)\n","        past_vals = np.concatenate((past_vals, past_answers.reshape(len(past_answers),1)), axis=1)\n","\n","        update_group_var(past_vals)  #Update database with the vals of the last batch        \n","        \n","    vals = test_data[[\"user_id\",\"content_id\",\"content_type_id\",\"timestamp\"]].values\n","    preds.extend(pred_users(vals))\n","    \n","    check = 1\n","\n","    pbar.update(len(test_data))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 254016/254021 [25:36<00:00, 80.02it/s]Wall time: 25min 36s\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = validation.iloc[:len(preds)]\n","df[\"preds\"] = preds\n","\n","df = df[df.content_type_id == False]\n","print('Validation ROC:',roc_auc_score(df.answered_correctly, df.preds))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation ROC: 0.7879732810648672\n","100%|██████████| 254021/254021 [25:51<00:00, 80.02it/s]"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.9.1-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}